{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.reshape(x_train, (-1,28,28,1))   #-1의 의미 : 뒤에를 28*28*1로 고정 나머지 계산 처리\n",
    "x_test = np.reshape(x_test, (-1,28,28,1))\n",
    "x_train.shape, x_test.shape   #흑백사진이므로 Channel 수가 1임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "y_train.shape, y_test.shape  #to_ategoircal : ㅒOne hot Encoding 해주는 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21b2cff2fd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.randint(1000)\n",
    "print(y_train[i])\n",
    "plt.imshow(x_train[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    validation_split = 0.25\n",
    ")\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_63 (Conv2D)           (None, 25, 25, 40)        680       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_63 (MaxPooling (None, 12, 12, 40)        0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 12, 12, 40)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 11, 11, 40)        6440      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_64 (MaxPooling (None, 5, 5, 40)          0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 5, 5, 40)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 4, 4, 40)          6440      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_65 (MaxPooling (None, 2, 2, 40)          0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 2, 2, 40)          0         \n",
      "_________________________________________________________________\n",
      "flatten_43 (Flatten)         (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 100)               16100     \n",
      "_________________________________________________________________\n",
      "flatten_44 (Flatten)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 30,670\n",
      "Trainable params: 30,670\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dropout_rate = 0.2\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(input_shape=(28,28,1), kernel_size=(4,4), filters=40, activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "    tf.keras.layers.Conv2D(kernel_size=(2,2), filters=40, activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "    tf.keras.layers.Conv2D(kernel_size=(2,2), filters=40, activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=100, activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics = ['accuracy']\n",
    "             )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "704/704 [==============================] - 34s 47ms/step - loss: 3.7552 - accuracy: 0.3360 - val_loss: 0.4092 - val_accuracy: 0.8775\n",
      "Epoch 2/20\n",
      "704/704 [==============================] - 31s 44ms/step - loss: 0.5606 - accuracy: 0.8169 - val_loss: 0.2711 - val_accuracy: 0.9182\n",
      "Epoch 3/20\n",
      "704/704 [==============================] - 31s 44ms/step - loss: 0.3849 - accuracy: 0.8753 - val_loss: 0.1928 - val_accuracy: 0.9413\n",
      "Epoch 4/20\n",
      "704/704 [==============================] - 31s 44ms/step - loss: 0.3128 - accuracy: 0.9006 - val_loss: 0.1612 - val_accuracy: 0.9487\n",
      "Epoch 5/20\n",
      "704/704 [==============================] - 31s 44ms/step - loss: 0.2673 - accuracy: 0.9155 - val_loss: 0.1409 - val_accuracy: 0.9584\n",
      "Epoch 6/20\n",
      "704/704 [==============================] - 31s 44ms/step - loss: 0.2260 - accuracy: 0.9288 - val_loss: 0.1225 - val_accuracy: 0.9612\n",
      "Epoch 7/20\n",
      "704/704 [==============================] - 32s 46ms/step - loss: 0.2081 - accuracy: 0.9334 - val_loss: 0.1086 - val_accuracy: 0.9675\n",
      "Epoch 8/20\n",
      "704/704 [==============================] - 31s 45ms/step - loss: 0.1879 - accuracy: 0.9419 - val_loss: 0.0940 - val_accuracy: 0.9703\n",
      "Epoch 9/20\n",
      "704/704 [==============================] - 32s 46ms/step - loss: 0.1810 - accuracy: 0.9437 - val_loss: 0.0940 - val_accuracy: 0.9711\n",
      "Epoch 10/20\n",
      "704/704 [==============================] - 32s 45ms/step - loss: 0.1689 - accuracy: 0.9488 - val_loss: 0.0891 - val_accuracy: 0.9726\n",
      "Epoch 11/20\n",
      "704/704 [==============================] - 33s 46ms/step - loss: 0.1648 - accuracy: 0.9480 - val_loss: 0.0753 - val_accuracy: 0.9761\n",
      "Epoch 12/20\n",
      "704/704 [==============================] - 32s 45ms/step - loss: 0.1539 - accuracy: 0.9521 - val_loss: 0.0780 - val_accuracy: 0.9767\n",
      "Epoch 13/20\n",
      "704/704 [==============================] - 32s 45ms/step - loss: 0.1484 - accuracy: 0.9524 - val_loss: 0.0783 - val_accuracy: 0.9758\n",
      "Epoch 14/20\n",
      "704/704 [==============================] - 33s 47ms/step - loss: 0.1327 - accuracy: 0.9598 - val_loss: 0.0770 - val_accuracy: 0.9769\n",
      "Epoch 15/20\n",
      "704/704 [==============================] - 32s 45ms/step - loss: 0.1417 - accuracy: 0.9569 - val_loss: 0.0702 - val_accuracy: 0.9791\n",
      "Epoch 16/20\n",
      "704/704 [==============================] - 32s 46ms/step - loss: 0.1359 - accuracy: 0.9575 - val_loss: 0.0787 - val_accuracy: 0.9776\n",
      "Epoch 17/20\n",
      "704/704 [==============================] - 33s 47ms/step - loss: 0.1349 - accuracy: 0.9572 - val_loss: 0.0738 - val_accuracy: 0.9783\n",
      "Epoch 18/20\n",
      "704/704 [==============================] - 32s 46ms/step - loss: 0.1287 - accuracy: 0.9603 - val_loss: 0.0658 - val_accuracy: 0.9800\n",
      "Epoch 19/20\n",
      "704/704 [==============================] - 32s 46ms/step - loss: 0.1295 - accuracy: 0.9610 - val_loss: 0.0662 - val_accuracy: 0.9811\n",
      "Epoch 20/20\n",
      "704/704 [==============================] - 32s 46ms/step - loss: 0.1264 - accuracy: 0.9615 - val_loss: 0.0649 - val_accuracy: 0.9799\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow(x_train, y_train, batch_size = 64, subset = 'training')\n",
    "val_generator = datagen.flow(x_train, y_train, batch_size = 64, subset = 'validation')\n",
    "\n",
    "history = model.fit_generator( train_generator,\n",
    "                               epochs = 20,\n",
    "                               verbose = 1,\n",
    "                               validation_data = val_generator,\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0370 - accuracy: 0.9882\n",
      "test loss : 0.03699154034256935 / test accuracy : 0.9882000088691711\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'test loss : {loss} / test accuracy : {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
